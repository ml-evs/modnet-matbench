{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODNet 'matbench_steels' benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `matbench_steels` dataset from [Citrination](https://citrination.com/datasets/153092/) (contributed by Gareth Conduit, University of Cambridge) contains the composition of ~800 steels and some measured properties with variable coverage. The dataset `matbench_steels` as made available by matminer has de-duplicated the steels down to ~312 samples, and provides only the measured yield strength, the property with 100% coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "from matminer.datasets import load_dataset\n",
    "from pymatgen.core import Composition\n",
    "\n",
    "from modnet.preprocessing import MODData\n",
    "#from modnet.models import MODNetModel\n",
    "from modnet.featurizers import MODFeaturizer\n",
    "from modnet.featurizers.presets import DeBreuck2020Featurizer\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modnet\n",
    "modnet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(filename=\"./README.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"matbench_steels\")\n",
    "df[\"composition\"] = df[\"composition\"].map(Composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composition space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df[\"composition\"].apply(lambda s: s.get_el_amt_dict())\n",
    "elements = defaultdict(float)\n",
    "proportions = defaultdict(list)\n",
    "for s in values:\n",
    "    for e in s:\n",
    "        elements[e] += s[e]\n",
    "        proportions[e] += [s[e]]\n",
    "        \n",
    "for elem in elements:\n",
    "    elements[elem] /= len(values)\n",
    "\n",
    "mean_proportions = {elem: np.mean(proportions[elem]) for elem in proportions}\n",
    "mean_proportions = dict(sorted(mean_proportions.items(), key=lambda x: x[1], reverse=True))\n",
    "elements = dict(sorted(elements.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"w\");\n",
    "ax.set_yscale(\"log\")\n",
    "ax.bar(elements.keys(), elements.values())\n",
    "ax.set_ylabel(\"Average concentration of element in dataset\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of element proportions across compositions\n",
    "fig, ax = plt.subplots(4, 4, facecolor=\"w\", figsize=(10, 10))\n",
    "for axis, elem in zip(itertools.product(range(0, 4), repeat=2), mean_proportions):\n",
    "    axis = (axis[1], axis[0])\n",
    "    ax[axis].hist(\n",
    "        proportions[elem], \n",
    "        bins=np.linspace(0, 1, 50), \n",
    "        density=False, \n",
    "    )\n",
    "    ax[axis].set_xlim(-0.1, 1.1)\n",
    "    ax[axis].text(0.75, 0.8, elem, fontsize=24, transform=ax[axis].transAxes, )\n",
    "    ax[axis].set_ylim(0, 312)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Target space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(facecolor=\"w\")\n",
    "ax.hist(df[\"yield strength\"], bins=100, density=True);\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_xlabel(\"Yield strength (GPa)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define some convenience classes that pass wraps composition data in a fake structure containe, and we define a composition only featurizer preset based on `DeBreuck2020Featurizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionOnlyFeaturizer(MODFeaturizer):\n",
    "    composition_featurizers = DeBreuck2020Featurizer.composition_featurizers\n",
    "    \n",
    "    def featurize_composition(self, df):\n",
    "        \"\"\" Applies the preset composition featurizers to the input dataframe,\n",
    "        renames some fields and cleans the output dataframe.\n",
    "\n",
    "        \"\"\"\n",
    "        from pymatgen.core.periodic_table import Element \n",
    "        import numpy as np\n",
    "        from modnet.featurizers import clean_df\n",
    "        df = super().featurize_composition(df)\n",
    "        _orbitals = {\"s\": 1, \"p\": 2, \"d\": 3, \"f\": 4}\n",
    "        df['AtomicOrbitals|HOMO_character'] = df['AtomicOrbitals|HOMO_character'].map(_orbitals)\n",
    "        df['AtomicOrbitals|LUMO_character'] = df['AtomicOrbitals|LUMO_character'].map(_orbitals)\n",
    "\n",
    "        df['AtomicOrbitals|HOMO_element'] = df['AtomicOrbitals|HOMO_element'].apply(\n",
    "            lambda x: -1 if not isinstance(x, str) else Element(x).Z\n",
    "        )\n",
    "        df['AtomicOrbitals|LUMO_element'] = df['AtomicOrbitals|LUMO_element'].apply(\n",
    "            lambda x: -1 if not isinstance(x, str) else Element(x).Z\n",
    "        )\n",
    "\n",
    "        df = df.replace([np.inf, -np.inf, np.nan], 0)\n",
    "        \n",
    "        return clean_df(df)\n",
    "\n",
    "class CompositionContainer:\n",
    "    def __init__(self, composition):\n",
    "        self.composition = composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECOMPUTED_MODDATA = \"./precomputed/steel_benchmark_moddata.pkl.gz\"\n",
    "\n",
    "if os.path.isfile(PRECOMPUTED_MODDATA):\n",
    "    data = MODData.load(PRECOMPUTED_MODDATA)\n",
    "else:\n",
    "    # Use a fresh copy of the dataset\n",
    "    df = load_dataset(\"matbench_steels\")\n",
    "    df[\"composition\"] = df[\"composition\"].map(Composition)\n",
    "    df[\"structure\"] = df[\"composition\"].map(CompositionContainer)\n",
    "    \n",
    "    data = MODData(\n",
    "        structures=df[\"structure\"].tolist(), \n",
    "        targets=df[\"yield strength\"].tolist(), \n",
    "        target_names=[\"yield strength (MPa)\"],\n",
    "        featurizer=CompositionOnlyFeaturizer(n_jobs=8)\n",
    "    )\n",
    "    data.featurize()\n",
    "    # As this is a small data/feature set, order all features \n",
    "    data.feature_selection(n=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.optimal_features=None\n",
    "#data.cross_nmi = None\n",
    "#data.num_classes = {\"yield strength (GPa)\":0}\n",
    "#data.feature_selection(n=-1)\n",
    "#data.save(\"./precomputed/steel_benchmark_moddata_MPCNMI.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at some of the top features chosen by MODNet\n",
    "for feat in data.optimal_features[:10]:\n",
    "    fig, ax = plt.subplots(facecolor=\"w\")\n",
    "    plt.scatter(data.df_featurized[feat], data.df_targets, alpha=0.5)\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(\"Yield strength (MPa)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very small dataset, so we must make judicious use of what data there is. First, let's generate test folds according to [matbench's suggestions](https://hackingmaterials.lbl.gov/automatminer/datasets.html#benchmarking-and-reporting-your-algorithm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    plot_benchmark\n",
    "except:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    from modnet_matbench.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from modnet.models import MODNetModel\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "data.df_targets.rename(columns={\"yield strength (GPa)\": \"sigma\"}, inplace=True)\n",
    "\n",
    "best_settings = {\n",
    "    \"increase_bs\":False,\n",
    "    \"num_neurons\": [[64], [32], [8], [8]],\n",
    "    \"n_feat\": 64,\n",
    "    \"lr\": 0.005,\n",
    "    \"epochs\": 500,\n",
    "    \"verbose\": 0,\n",
    "    \"act\": \"elu\",\n",
    "    \"batch_size\": 32,\n",
    "    \"loss\": \"mae\",\n",
    "    \"xscale\": \"standard\",\n",
    "}\n",
    "\n",
    "results = matbench_benchmark(data, [[[\"sigma\"]]], {\"sigma\": 1}, best_settings,save_folds=True)\n",
    "np.mean(results['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#best_settings = {\n",
    "#    \"increase_bs\":True,\n",
    "#    \"num_neurons\": [[32], [32], [8], [8]],\n",
    "#    \"n_feat\": 35,\n",
    "#    \"lr\": 0.1,\n",
    "#    \"epochs\": 500,\n",
    "#    \"verbose\": 0,\n",
    "#    \"act\": \"relu\",\n",
    "#    \"batch_size\": 32,\n",
    "#    \"loss\": \"mae\",\n",
    "#    \"xscale\": \"minmax\",\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i,c in zip(range(5),['b','k','r','g','y']):\n",
    "    plt.plot(results[\"models\"][i].history.history[\"loss\"][50:],c=c)\n",
    "    plt.plot(results[\"models\"][i].history.history[\"val_loss\"][50:],':',c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,c in zip(range(5),['b','k','r','g','y']):\n",
    "    plt.plot(results[\"models\"][i].history.history[\"loss\"][50:],c=c)\n",
    "    plt.plot(results[\"models\"][i].history.history[\"val_loss\"][50:],':',c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,c in zip(range(5),['b','k','r','g','y']):\n",
    "    plt.plot(results[\"models\"][i].history.history[\"loss\"][50:],c=c)\n",
    "    plt.plot(results[\"models\"][i].history.history[\"val_loss\"][50:],':',c=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "reg_df = pd.DataFrame(\n",
    "    np.array([\n",
    "        [x for targ in results[\"targets\"] for x in targ],\n",
    "        [y for pred in results[\"predictions\"] for y in pred],\n",
    "        [e for err in results[\"errors\"] for e in err]\n",
    "    ]).T,\n",
    "    columns=[\"targets\", \"predictions\", \"errors\"]\n",
    ")\n",
    "splits = []\n",
    "for i in range(5):\n",
    "    for j in range(len(results[\"targets\"][i])):\n",
    "        splits.append(i)\n",
    "reg_df[\"split\"] = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.set_aspect(\"equal\")\n",
    "sns.scatterplot(data=reg_df, x=\"targets\", y=\"predictions\", hue=\"split\", palette=\"Dark2\", ax=ax, alpha=0.5)\n",
    "sns.regplot(data=reg_df, x=\"targets\", y=\"predictions\", ax=ax, scatter=False, color=\"k\")\n",
    "# plt.plot(*ax.get_xlim(), *ax.get_xlim(), c=\"k\",alpha=0.5)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Pred.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.jointplot(data=reg_df, x=\"targets\", y=\"predictions\", hue=\"split\", palette=\"Dark2\", alpha=0.0, marginal_kws={\"shade\": False})\n",
    "g.plot_joint(sns.scatterplot, hue=None, c=\"black\", s=5, alpha=0.8)\n",
    "g.plot_joint(sns.kdeplot, color=\"split\", zorder=0, levels=5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    x = data.get_featurized_df()[model.optimal_descriptors[:model.n_feat]]\n",
    "    x = model._scaler.transform(x)\n",
    "    x = np.nan_to_num(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    matbench_kfold_splits()\n",
    "except:\n",
    "    os.chdir(\"..\")\n",
    "    from modnet_matbench.utils import matbench_kfold_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "for train, test in matbench_kfold_splits(data):\n",
    "    train_moddata, test_moddata = data.split((train, test))\n",
    "    break\n",
    "\n",
    "X_train = shap.sample(process(train_moddata))\n",
    "explainer = shap.KernelExplainer(model.model.predict, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_train, nsamples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value, \n",
    "    shap_values[0], \n",
    "    feature_names=model.optimal_descriptors[:model.n_feat], \n",
    "    out_names=[\"Yield strength (GPa)\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], X_train, max_display=32, plot_type=\"dot\", feature_names=model.optimal_descriptors[:model.n_feat])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (modnet-develop)",
   "language": "python",
   "name": "modnet-develop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}